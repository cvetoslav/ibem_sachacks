{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a42d043-e9b5-417d-8fb7-5dbb44999b4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Machine Learning aided **Task prioritization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29238998-77a5-40e5-8fac-af5450d028ca",
   "metadata": {},
   "source": [
    "Import the libraries and setup the **keywords**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa453908-6f95-4c26-a538-dd475487bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "data = []\n",
    "primes = []\n",
    "keywords = [\"add\", \"delete\", \"edit\", \"implement\", \"comment\", \"create\", \"update\", \"fix\", \"set\", \"use\", \"provide\", \"text\",\n",
    "            \"write\", \"read\", \"dm\", \"call\", \"email\", \"tell\", \"prevent\", \"notify\", \"finish\", \"convert\", \"do\", \"buy\",\n",
    "            \"deliver\", \"execute\", \"test\", \"sell\", \"open\", \"close\", \"stop\", \"continue\", \"cancel\", \"build\", \"merge\",\n",
    "            \"replace\", \"swap\", \"fax\", \"mail\", \"important\", \"vital\", \"soon\", \"urgent\", \"emergency\", \"address\", \"issue\",\n",
    "            \"problem\", \"discontinue\", \"take\", \"find\"]\n",
    "\n",
    "n = len(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669552e-db41-4f0c-b619-7703e92667e6",
   "metadata": {},
   "source": [
    "Define the encoding function needed for extraction of the frequency domain of the keywords occurrences in the given text. This will be used for the input data of the neural network model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba749e-d51f-4cac-a7cf-0dba11bd88b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate({ord(i): ' ' for i in '.,/!?[]()*&_-\\\\|#'})\n",
    "    enc = []\n",
    "    for i in range(n):\n",
    "        enc.append(text.count(keywords[i]))\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e87192-61be-4801-a924-a6275e6017a3",
   "metadata": {},
   "source": [
    "Extract the training data and 'labels' (Priorities assigned to every task description by the user from 0 to 9 as 0 being the highest priority):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67324983-8dd7-479d-a430-a5775e94c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_prios = []\n",
    "\n",
    "for f in os.listdir('data/train/tasks'):\n",
    "    train_data.append(encode_text(open('data/train/tasks/' + f).read()))\n",
    "    ls = [0 for i in range(10)]\n",
    "    ls[int(open('data/train/rating/' + f).read())] = 1\n",
    "    train_prios.append(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c88f6f-4289-46b4-bf3b-3f2f8038b68d",
   "metadata": {},
   "source": [
    "Then configure our ML model, which consists of input layer denoting the frequency of every keyword [size: n] two hidden *dense* layers with ReLU (rectified linear unit) activations and final output layer with 10 nodes each denoting the probability of the **predicted priority** to be respectively 1 to 10, again 1 being the highest possible priority value.\n",
    "We then run the model training for about 300 epochs since our dataset consists of barely 60 records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97bc24-3a8a-434f-a898-dfc74c64a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_dim=n),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_prios, epochs=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21213f-23ba-416f-8cd9-6e6172665331",
   "metadata": {},
   "source": [
    "Now let's test how the model is reacting to new inputs from the test dataset.\n",
    "To summarize the results of the neural network we calculate the expected value of the priority by adding the products of probability and sub-priority together. Then this is our final prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6748c45a-3bc5-4beb-97aa-68b129db97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for f in os.listdir('data/test'):\n",
    "    test_data.append(encode_text(open('data/test/' + f).read()))\n",
    "\n",
    "for ls in model.predict(test_data):\n",
    "    res = 0\n",
    "    for i in range(10):\n",
    "        res += (i+1) * ls[i]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a750831f-56ca-442c-b2a7-042eb16442e6",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "7.040407248932752\n",
    "2.962369019017029"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e7022-2734-48c4-84f1-d3ad175f7263",
   "metadata": {},
   "source": [
    "The tests were the following:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4746a2a-c4c4-4898-8e5e-b23e17590e6f",
   "metadata": {},
   "source": [
    "Finish my final research project about the different kinds of penguins in Antarctica."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3bb8b29-28f4-4628-b732-4a80f59a0b2b",
   "metadata": {},
   "source": [
    "Write an important mail to Mr. Schwarz soon to tell him that I resolved the issue with the implementation of the e-mail service.\n",
    "I added tls support, urgently replaced the bugging code, and added some test results. Later I will think of some new features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43568269-f900-4799-81eb-ee734e6a7592",
   "metadata": {},
   "source": [
    "As we see the second task gets way higher priority than the first one, mainly because of having some very important *keywords* like: **important** and **urgent**.\n",
    "\n",
    "Thus we can conclude that despite our very small dataset of self written task descriptions and labeling the model we constructed is beginning to grasp some important concepts of our main idea. Of course to become way more accurate and consistant in the output, long time of data collecting, labeling and training is needed.\n",
    "\n",
    "This is why the project is aimed to be self developing, which means that the model has to adapt to the given user input dynamically. For example the AI suggests you some ordering of your tasks in the Web App, but you think some other configuration would be better for you and reorder them in the online form. Well, congratulations! You helped us improve our ML model by contributing another training data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
